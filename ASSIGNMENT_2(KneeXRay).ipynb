{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "280430c3ac5c4a3dbea757db8205579e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5060af2ad904324a1f633d3bd0a393d",
              "IPY_MODEL_bea6cfe6fcfd4b9dbb90a8cc6c176cd0",
              "IPY_MODEL_cd030cb90170452e9d98640a778e1fd7"
            ],
            "layout": "IPY_MODEL_ac42e0658bf64709973f4fe92adb8f07"
          }
        },
        "b5060af2ad904324a1f633d3bd0a393d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6d82f7b06554e60b3a1f412ff45969c",
            "placeholder": "​",
            "style": "IPY_MODEL_57c62a7e47994abf9daf0030b81c4589",
            "value": "100%"
          }
        },
        "bea6cfe6fcfd4b9dbb90a8cc6c176cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e104db13d4804f348d16f02d14e025f2",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f376cf150414d9fb7327cb6c93aca70",
            "value": 46830571
          }
        },
        "cd030cb90170452e9d98640a778e1fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5771496f54e9419ab24b93a3cda0e5e3",
            "placeholder": "​",
            "style": "IPY_MODEL_29c8cb45adf543548b08a45ece1a2c2c",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 113MB/s]"
          }
        },
        "ac42e0658bf64709973f4fe92adb8f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d82f7b06554e60b3a1f412ff45969c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57c62a7e47994abf9daf0030b81c4589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e104db13d4804f348d16f02d14e025f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f376cf150414d9fb7327cb6c93aca70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5771496f54e9419ab24b93a3cda0e5e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c8cb45adf543548b08a45ece1a2c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gu5EoMTZpGPe"
      },
      "outputs": [],
      "source": [
        "## QUESTION 1\n",
        "\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Transforms to the Data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "image_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n"
      ],
      "metadata": {
        "id": "_zXnO5f66fIE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zW8_LRj7lpj",
        "outputId": "15348e18-dd0d-4ed7-e7a0-1fbbfbbc7b97"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGWbs8c-pGPr",
        "outputId": "81728284-af17-4e91-9cd4-4294d4d66593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "# Load the Data\n",
        "\n",
        "# Set train and valid directory paths\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "dataset ='/content/gdrive/MyDrive/KneeXRay'\n",
        "\n",
        "train_directory = os.path.join(dataset, 'train')\n",
        "test_directory = os.path.join(dataset, 'validation')\n",
        "\n",
        "# Batch size\n",
        "batchSize = 32\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(os.listdir(train_directory))\n",
        "print(num_classes)\n",
        "\n",
        "# Load Data from folders\n",
        "data = {\n",
        "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
        "\n",
        "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
        "}\n",
        "\n",
        "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
        "# idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
        "# print(idx_to_class)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4oXlilr6zcf",
        "outputId": "0b44d0e3-ad46-4b9e-d208-7397617569ae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 5778\n",
              "    Root location: /content/gdrive/MyDrive/KneeXRay/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               RandomResizedCrop(size=(256, 256), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
              "               RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
              "               RandomHorizontalFlip(p=0.5)\n",
              "               CenterCrop(size=(224, 224))\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
        "train_data_size = len(data['train'])\n",
        "# valid_data_size = len(data['valid'])\n",
        "test_data_size = len(data['test'])\n",
        "\n",
        "# Create iterators for the Data loaded using DataLoader module\n",
        "trainloader = DataLoader(data['train'], batch_size=batchSize, shuffle=True)\n",
        "# valid_data_loader = DataLoader(data['valid'], batch_size=batchSize, shuffle=True)\n",
        "testloader = DataLoader(data['test'], batch_size=batchSize, shuffle=True)"
      ],
      "metadata": {
        "id": "5h0X1aze61RD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################\n",
        "# DEFINE YOUR OWN MODEL\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 10.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "#######################\n",
        "\n",
        "# 2. LOSS AND OPTIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 3. move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model_ft.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "280430c3ac5c4a3dbea757db8205579e",
            "b5060af2ad904324a1f633d3bd0a393d",
            "bea6cfe6fcfd4b9dbb90a8cc6c176cd0",
            "cd030cb90170452e9d98640a778e1fd7",
            "ac42e0658bf64709973f4fe92adb8f07",
            "e6d82f7b06554e60b3a1f412ff45969c",
            "57c62a7e47994abf9daf0030b81c4589",
            "e104db13d4804f348d16f02d14e025f2",
            "1f376cf150414d9fb7327cb6c93aca70",
            "5771496f54e9419ab24b93a3cda0e5e3",
            "29c8cb45adf543548b08a45ece1a2c2c"
          ]
        },
        "id": "ASrqTBUC7Hug",
        "outputId": "83d3ae33-8794-44b0-c545-0496fa6fd24f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "280430c3ac5c4a3dbea757db8205579e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time # to calculate training time\n",
        "\n",
        "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
        "    '''\n",
        "    Function to train and validate\n",
        "    Parameters\n",
        "        :param model: Model to train and validate\n",
        "        :param loss_criterion: Loss Criterion to minimize\n",
        "        :param optimizer: Optimizer for computing gradients\n",
        "        :param epochs: Number of epochs (default=25)\n",
        "  \n",
        "    Returns\n",
        "        model: Trained Model with best validation accuracy\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
        "    '''\n",
        "    \n",
        "    start = time.time()\n",
        "    history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
        "        \n",
        "        # Set to training mode\n",
        "        model.train()\n",
        "        \n",
        "        # Loss and Accuracy within the epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        \n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Clean existing gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            \n",
        "            # Backpropagate the gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Compute the total loss for the batch and add it to train_loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            # Compute the accuracy\n",
        "            ret, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "            \n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "            \n",
        "            # Compute total accuracy in the whole batch and add to train_acc\n",
        "            train_acc += acc.item() * inputs.size(0)\n",
        "            \n",
        "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
        "\n",
        "            \n",
        "        # Validation - No gradient tracking needed\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for j, (inputs, labels) in enumerate(testloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass - compute outputs on input data using the model\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_criterion(outputs, labels)\n",
        "\n",
        "                # Compute the total loss for the batch and add it to valid_loss\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                ret, predictions = torch.max(outputs.data, 1)\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "                # Convert correct_counts to float and then compute the mean\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\n",
        "                valid_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
        "            \n",
        "        # Find average training loss and training accuracy\n",
        "        avg_train_loss = train_loss/train_data_size \n",
        "        avg_train_acc = train_acc/train_data_size\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_test_loss = valid_loss/test_data_size \n",
        "        avg_test_acc = valid_acc/test_data_size\n",
        "\n",
        "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
        "                \n",
        "        epoch_end = time.time()\n",
        "    \n",
        "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_test_loss, avg_test_acc*100, epoch_end-epoch_start))\n",
        "        \n",
        "        # Save if the model has best accuracy till now\n",
        "        torch.save(model, 'kneeXray_model_'+str(epoch)+'.pt')\n",
        "            \n",
        "    return model, history"
      ],
      "metadata": {
        "id": "Od2vn7pH7Nvh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train the model for 10 epochs\n",
        " \n",
        "num_epochs = 10\n",
        "trained_model, history = train_and_validate(model_ft, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R2o3LlD7S0e",
        "outputId": "5b6f6e89-2646-43d0-d06f-d74d951e0ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/10\n",
            "Epoch : 000, Training: Loss: 1.3284, Accuracy: 43.8387%, \n",
            "\t\tValidation : Loss : 1.2375, Accuracy: 47.4576%, Time: 2613.2398s\n",
            "Epoch: 2/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## QUESTION 2\n",
        "import os\n",
        "\n",
        "#Numpy is linear algebra lbrary\n",
        "import numpy as np\n",
        "# Matplotlib is a visualizations library \n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "a1mZrmWTK5Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.Resize(64),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.KneeXRay(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.KneeXRay(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('healthy', 'doubtful', 'minimal', 'moderate',\n",
        "       'severe')\n",
        "\n",
        "KneeXRay_labels = [\"healthy\",      # index 0\n",
        "                   \"doubtful\",     # index 1\n",
        "                   \"minimal\",      # index 2 \n",
        "                   \"moderate\",     # index 3 \n",
        "                   \"severe\"]       # index 4\n",
        "\n",
        "train_data_size = len(trainloader.dataset)\n",
        "test_data_size = len(testloader.dataset)\n",
        "\n",
        "print(train_data_size)\n",
        "print(test_data_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "78dd2cd60ddf4f509a25f6f241b2ba4b",
            "c379191c79514e9299ba6cdd081cc1c3",
            "4f1620a76a8047c2a8b2bc6229a95ebd",
            "ebaf4a481f104a60922fb4b7926174a9",
            "c56e27f97c2843999595004bf7c633e6",
            "d88412dc38f44cef8c66a70f41f9e204",
            "72c6ae61fcfd49378efe20bbef02063d",
            "b8569797828446d7b7c8609f63b9cda0",
            "476828b2d57646bc8d4bcad2007e010e",
            "5e243bfd1ade475a9c40fcade1291635",
            "113053f1b7924832badf37993b90c8ff"
          ]
        },
        "id": "FJWzORaHLFby",
        "outputId": "0984ecb9-d91a-4afc-cd90-9decc51ddde0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78dd2cd60ddf4f509a25f6f241b2ba4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "50000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. DEFINE THE CNN \n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(10, 15, 3)\n",
        "        self.batchnorm = nn.BatchNorm2d(15)\n",
        "        self.conv3 = nn.Conv2d(15, 20, 3)\n",
        "        self.fc1 = nn.Linear(20 * 6 * 6, 100)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 20 * 6 * 6)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7jW2QTV9LOmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN() # need to instantiate the network to be used in instance method\n",
        "\n",
        "# 2. LOSS AND OPTIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 3. move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHnNhEdTLUKj",
        "outputId": "1f04366e-211f-478c-aad6-0192e284e82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(10, 15, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batchnorm): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(15, 20, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=720, out_features=100, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time # to calculate training time\n",
        "\n",
        "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
        "    '''\n",
        "    Function to train and validate\n",
        "    Parameters\n",
        "        :param model: Model to train and validate\n",
        "        :param loss_criterion: Loss Criterion to minimize\n",
        "        :param optimizer: Optimizer for computing gradients\n",
        "        :param epochs: Number of epochs (default=25)\n",
        "  \n",
        "    Returns\n",
        "        model: Trained Model with best validation accuracy\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
        "    '''\n",
        "    \n",
        "    start = time.time()\n",
        "    history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
        "        \n",
        "        # Set to training mode\n",
        "        model.train()\n",
        "        \n",
        "        # Loss and Accuracy within the epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        \n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Clean existing gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            \n",
        "            # Backpropagate the gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Compute the total loss for the batch and add it to train_loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            # Compute the accuracy\n",
        "            ret, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "            \n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "            \n",
        "            # Compute total accuracy in the whole batch and add to train_acc\n",
        "            train_acc += acc.item() * inputs.size(0)\n",
        "            \n",
        "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
        "\n",
        "            \n",
        "        # Validation - No gradient tracking needed\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for j, (inputs, labels) in enumerate(testloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass - compute outputs on input data using the model\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_criterion(outputs, labels)\n",
        "\n",
        "                # Compute the total loss for the batch and add it to valid_loss\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                ret, predictions = torch.max(outputs.data, 1)\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "                # Convert correct_counts to float and then compute the mean\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\n",
        "                valid_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
        "            \n",
        "        # Find average training loss and training accuracy\n",
        "        avg_train_loss = train_loss/train_data_size \n",
        "        avg_train_acc = train_acc/train_data_size\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_test_loss = valid_loss/test_data_size \n",
        "        avg_test_acc = valid_acc/test_data_size\n",
        "\n",
        "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
        "                \n",
        "        epoch_end = time.time()\n",
        "    \n",
        "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_test_loss, avg_test_acc*100, epoch_end-epoch_start))\n",
        "        \n",
        "        # Save if the model has best accuracy till now\n",
        "        torch.save(model, 'cifar10_model_'+str(epoch)+'.pt')\n",
        "            \n",
        "    return model, history"
      ],
      "metadata": {
        "id": "MajvU3IULWFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Train the model for 10 epochs\n",
        "\n",
        "num_epochs = 10\n",
        "trained_model, history = train_and_validate(model, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgI5C_ysLcyl",
        "outputId": "1847f0d5-7b0b-4c9f-9b90-1576612b7ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10\n",
            "Epoch : 000, Training: Loss: 1.4986, Accuracy: 45.8360%, \n",
            "\t\tValidation : Loss : 1.2048, Accuracy: 56.4800%, Time: 87.8540s\n",
            "Epoch: 2/10\n",
            "Epoch : 001, Training: Loss: 1.1790, Accuracy: 58.3220%, \n",
            "\t\tValidation : Loss : 1.0652, Accuracy: 62.5400%, Time: 76.5544s\n",
            "Epoch: 3/10\n",
            "Epoch : 002, Training: Loss: 1.0637, Accuracy: 62.4460%, \n",
            "\t\tValidation : Loss : 1.0186, Accuracy: 64.4900%, Time: 77.5292s\n",
            "Epoch: 4/10\n",
            "Epoch : 003, Training: Loss: 0.9942, Accuracy: 64.9520%, \n",
            "\t\tValidation : Loss : 0.9545, Accuracy: 66.9000%, Time: 76.5749s\n",
            "Epoch: 5/10\n",
            "Epoch : 004, Training: Loss: 0.9338, Accuracy: 67.0940%, \n",
            "\t\tValidation : Loss : 0.9295, Accuracy: 67.8000%, Time: 76.9348s\n",
            "Epoch: 6/10\n",
            "Epoch : 005, Training: Loss: 0.8926, Accuracy: 68.6200%, \n",
            "\t\tValidation : Loss : 0.9435, Accuracy: 67.9900%, Time: 76.9632s\n",
            "Epoch: 7/10\n",
            "Epoch : 006, Training: Loss: 0.8552, Accuracy: 69.9160%, \n",
            "\t\tValidation : Loss : 0.9205, Accuracy: 68.4300%, Time: 76.9442s\n",
            "Epoch: 8/10\n",
            "Epoch : 007, Training: Loss: 0.8243, Accuracy: 70.8340%, \n",
            "\t\tValidation : Loss : 0.9329, Accuracy: 68.3600%, Time: 78.2034s\n",
            "Epoch: 9/10\n",
            "Epoch : 008, Training: Loss: 0.8054, Accuracy: 71.5820%, \n",
            "\t\tValidation : Loss : 0.9445, Accuracy: 68.5800%, Time: 75.7242s\n",
            "Epoch: 10/10\n",
            "Epoch : 009, Training: Loss: 0.7773, Accuracy: 72.6700%, \n",
            "\t\tValidation : Loss : 0.8895, Accuracy: 70.0000%, Time: 76.0050s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## QUESTION 3\n",
        "\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "t_yzWlJRuWel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Veui89ripGPp"
      },
      "outputs": [],
      "source": [
        "# Applying Transforms to the Data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "image_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(size=256),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfbf8101-784a-4db4-fdc7-fdca3b1d3bba",
        "id": "4-CqSlbgu6aT"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# Load the Data\n",
        "\n",
        "# Set train and valid directory paths\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "dataset ='/content/gdrive/MyDrive/KneeXRay'\n",
        "\n",
        "train_directory = os.path.join(dataset, 'train')\n",
        "test_directory = os.path.join(dataset, 'validation')\n",
        "\n",
        "# Batch size\n",
        "batchSize = 32\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(os.listdir(train_directory))\n",
        "print(num_classes)\n",
        "\n",
        "# Load Data from folders\n",
        "data = {\n",
        "    'train': datasets.ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
        "\n",
        "    'test': datasets.ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
        "}\n",
        "\n",
        "# Get a mapping of the indices to the class names, in order to see the output classes of the test images.\n",
        "# idx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\n",
        "# print(idx_to_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuZoH8SVpGPu"
      },
      "outputs": [],
      "source": [
        "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
        "train_data_size = len(data['train'])\n",
        "# valid_data_size = len(data['valid'])\n",
        "test_data_size = len(data['test'])\n",
        "\n",
        "# Create iterators for the Data loaded using DataLoader module\n",
        "trainloader = DataLoader(data['train'], batch_size=batchSize, shuffle=True)\n",
        "# valid_data_loader = DataLoader(data['valid'], batch_size=batchSize, shuffle=True)\n",
        "testloader = DataLoader(data['test'], batch_size=batchSize, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7TYXzQ4pGPy",
        "outputId": "4db98a9b-3d75-404a-e6b8-c3f14fb82c35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ConvNeXt_Tiny_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Tiny_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNeXt(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
              "      )\n",
              "      (3): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
              "      )\n",
              "      (4): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
              "      )\n",
              "      (5): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
              "      )\n",
              "      (6): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
              "      )\n",
              "      (7): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
              "      )\n",
              "      (8): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
              "      )\n",
              "      (1): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
              "      )\n",
              "      (2): CNBlock(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
              "          (1): Permute()\n",
              "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (4): GELU(approximate=none)\n",
              "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (6): Permute()\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=768, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#######################\n",
        "# DEFINE YOUR OWN MODEL\n",
        "\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 10.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "#######################\n",
        "\n",
        "# 2. LOSS AND OPTIMIZER\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 3. move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model_ft.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEVE8du9pGPz"
      },
      "outputs": [],
      "source": [
        "import time # to calculate training time\n",
        "\n",
        "def train_and_validate(model, loss_criterion, optimizer, epochs=25):\n",
        "    '''\n",
        "    Function to train and validate\n",
        "    Parameters\n",
        "        :param model: Model to train and validate\n",
        "        :param loss_criterion: Loss Criterion to minimize\n",
        "        :param optimizer: Optimizer for computing gradients\n",
        "        :param epochs: Number of epochs (default=25)\n",
        "  \n",
        "    Returns\n",
        "        model: Trained Model with best validation accuracy\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
        "    '''\n",
        "    \n",
        "    start = time.time()\n",
        "    history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
        "        \n",
        "        # Set to training mode\n",
        "        model.train()\n",
        "        \n",
        "        # Loss and Accuracy within the epoch\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "        \n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "        \n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Clean existing gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            \n",
        "            # Backpropagate the gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Compute the total loss for the batch and add it to train_loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            # Compute the accuracy\n",
        "            ret, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "            \n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "            \n",
        "            # Compute total accuracy in the whole batch and add to train_acc\n",
        "            train_acc += acc.item() * inputs.size(0)\n",
        "            \n",
        "            #print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n",
        "\n",
        "            \n",
        "        # Validation - No gradient tracking needed\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Set to evaluation mode\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for j, (inputs, labels) in enumerate(testloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass - compute outputs on input data using the model\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_criterion(outputs, labels)\n",
        "\n",
        "                # Compute the total loss for the batch and add it to valid_loss\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                ret, predictions = torch.max(outputs.data, 1)\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "                # Convert correct_counts to float and then compute the mean\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\n",
        "                valid_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "                #print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
        "            \n",
        "        # Find average training loss and training accuracy\n",
        "        avg_train_loss = train_loss/train_data_size \n",
        "        avg_train_acc = train_acc/train_data_size\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_test_loss = valid_loss/test_data_size \n",
        "        avg_test_acc = valid_acc/test_data_size\n",
        "\n",
        "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
        "                \n",
        "        epoch_end = time.time()\n",
        "    \n",
        "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_test_loss, avg_test_acc*100, epoch_end-epoch_start))\n",
        "        \n",
        "        # Save if the model has best accuracy till now\n",
        "        torch.save(model, 'KneeXRay_model_'+str(epoch)+'.pt')\n",
        "            \n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9tt7xW0pGP0",
        "outputId": "1e70dbd2-5bea-4e3d-ea7d-675a74dfbdb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10\n",
            "Epoch : 000, Training: Loss: 1.3151, Accuracy: 34.4538%, \n",
            "\t\tValidation : Loss : 0.8873, Accuracy: 68.0000%, Time: 10.3635s\n",
            "Epoch: 2/10\n",
            "Epoch : 001, Training: Loss: 0.7483, Accuracy: 63.0252%, \n",
            "\t\tValidation : Loss : 0.6391, Accuracy: 70.6667%, Time: 6.5631s\n",
            "Epoch: 3/10\n",
            "Epoch : 002, Training: Loss: 0.5991, Accuracy: 76.4706%, \n",
            "\t\tValidation : Loss : 0.5654, Accuracy: 74.6667%, Time: 6.6185s\n",
            "Epoch: 4/10\n",
            "Epoch : 003, Training: Loss: 0.4952, Accuracy: 80.6723%, \n",
            "\t\tValidation : Loss : 0.4982, Accuracy: 82.6667%, Time: 6.6025s\n",
            "Epoch: 5/10\n",
            "Epoch : 004, Training: Loss: 0.4082, Accuracy: 87.3950%, \n",
            "\t\tValidation : Loss : 0.4335, Accuracy: 84.0000%, Time: 6.6484s\n",
            "Epoch: 6/10\n",
            "Epoch : 005, Training: Loss: 0.3509, Accuracy: 89.0756%, \n",
            "\t\tValidation : Loss : 0.3888, Accuracy: 88.0000%, Time: 6.6027s\n",
            "Epoch: 7/10\n",
            "Epoch : 006, Training: Loss: 0.2997, Accuracy: 93.2773%, \n",
            "\t\tValidation : Loss : 0.3749, Accuracy: 86.6667%, Time: 6.6217s\n",
            "Epoch: 8/10\n",
            "Epoch : 007, Training: Loss: 0.2298, Accuracy: 92.4370%, \n",
            "\t\tValidation : Loss : 0.3194, Accuracy: 92.0000%, Time: 6.6229s\n",
            "Epoch: 9/10\n",
            "Epoch : 008, Training: Loss: 0.1932, Accuracy: 92.4370%, \n",
            "\t\tValidation : Loss : 0.2948, Accuracy: 90.6667%, Time: 6.5470s\n",
            "Epoch: 10/10\n",
            "Epoch : 009, Training: Loss: 0.1433, Accuracy: 96.6387%, \n",
            "\t\tValidation : Loss : 0.2723, Accuracy: 90.6667%, Time: 6.9166s\n"
          ]
        }
      ],
      "source": [
        "# 4. Train the model for 10 epochs\n",
        " \n",
        "num_epochs = 10\n",
        "trained_model, history = train_and_validate(model_ft, criterion, optimizer, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## QUESTION 4"
      ],
      "metadata": {
        "id": "RRigqpfH_BK-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}